var documenterSearchIndex = {"docs":
[{"location":"tuto/oneplusone_onemax.html#1-EA-for-maximising-a-pseudoboolean-function","page":"The OneMax problem","title":"1+1 EA for maximising a pseudoboolean function","text":"","category":"section"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"This tutorial showcases how to use the built-in 1+1 Evolutionary Algorithm (EA).","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"First, we import our modules like so:","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"using EvoLP\nusing OrderedCollections\nusing Statistics","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"For this example, we will use the onemax test function, which is already included in EvoLP:","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"@doc onemax","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"The OneMax function returns the sum of the individual. For an individual of length n, maximum is achieved with n ones.textOneMax(mathbfx) = sum_i=1^n x_i","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"In an EA we use vectors as individuals. The 1+1 EA features 1 parent and 1 offspring each iteration.","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"Let's start creating the first individual. We can generate it manually, or use a generator. Let's do the latter:","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"@doc binary_vector_pop","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"binary_vector_pop(n, l; rng=Random.GLOBAL_RNG)","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"Generate a population of n vector binary individuals, each of length l.","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"It is important to note that the return value of the binary_vector_pop generator is a  population:  a list. This means we only want the first (and only) element inside:","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"ind_size = 15\nfirstborn = binary_vector_pop(1, ind_size)[1]","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"15-element BitVector:\n    0\n    0\n    1\n    1\n    0\n    0\n    1\n    0\n    0\n    1\n    1\n    0\n    1\n    0\n    1","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"Since the 1+1 EA works on a single individual, we only have the mutation step. We can set up the appropriate mutation operator: BitwiseMutation.","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"@doc BitwiseMutation","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"Bitwise mutation with probability Î» of flipping each bit.","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"This mutation operator needs a probability lambda for flipping each bit, so we pass it like so:","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"Mut = BitwiseMutation(1/ind_size)","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"BitwiseMutation(0.06666666666666667)","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"Now on to the fitness function. Since EvoLP is built for minimisation, in order to do maximisation we need to optimise for the negative of OneMax:","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"f(x) = -onemax(x)","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"f (generic function with 1 method)","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"Let's use the Logbook to record the fitness value on each iteration. We can do so by the Base.identity function as it will return the same value as the fitness:","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"statnames = [\"fit\"]\ncallables = [identity]\nthedict = LittleDict(statnames, callables)\nlogbook = Logbook(thedict)","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"Logbook(LittleDict{AbstractString, Function, Vector{AbstractString}, Vector{Function}}(\"fit\" => identity), NamedTuple{(:fit,)}[])","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"We are now ready to use the oneplusone built-in algorithm:","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"@doc oneplusone","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"oneplusone(f::Function, ind, k_max, M)\noneplusone(logger::Logbook, f::Function, ind, k_max, M)","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"1+1 EA algorithm.Argumentsf: Objective function to minimise\nind: Individual to start the evolution\nk_max: Maximum number of iterations\nM::MutationMethod: A mutation method. See mutation.Returns a Result.","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"result = oneplusone(logbook, f, firstborn, 50, Mut);","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"The output was suppressed so that we can analyse each part of the result separately using the Result functions:","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"@show optimum(result)\n@show optimizer(result)\n@show iterations(result)\n@show f_calls(result)","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"optimum(result) = -15\noptimizer(result) = Bool[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\niterations(result) = 50\nf_calls(result) = 102","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"We can also take a look at the logbook records and see how the statistics changed throughout the run (although in this case we just logged the fitness):","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"first(logbook.records, 20)","category":"page"},{"location":"tuto/oneplusone_onemax.html","page":"The OneMax problem","title":"The OneMax problem","text":"20-element Vector{NamedTuple{(:fit,)}}:\n    (fit = [-7],)\n    (fit = [-7],)\n    (fit = [-8],)\n    (fit = [-9],)\n    (fit = [-9],)\n    (fit = [-9],)\n    (fit = [-9],)\n    (fit = [-9],)\n    (fit = [-9],)\n    (fit = [-9],)\n    (fit = [-9],)\n    (fit = [-9],)\n    (fit = [-9],)\n    (fit = [-10],)\n    (fit = [-10],)\n    (fit = [-10],)\n    (fit = [-10],)\n    (fit = [-11],)\n    (fit = [-11],)\n    (fit = [-11],)","category":"page"},{"location":"references.html#References-and-related-links","page":"References & related links","title":"References and related links","text":"","category":"section"},{"location":"references.html","page":"References & related links","title":"References & related links","text":"EvoLP is heavily inspired by other packages and scientific works.","category":"page"},{"location":"references.html#Related-Packages","page":"References & related links","title":"Related Packages","text":"","category":"section"},{"location":"references.html#Julia","page":"References & related links","title":"Julia","text":"","category":"section"},{"location":"references.html","page":"References & related links","title":"References & related links","text":"Metaheuristics is a package with metaheuristic solvers of all kinds.\nEvolutionary contains multiple GAs and EAs implementations.\nGeneticAlgorithms is a somewhat outdated package for writing GAs.\nBlackBoxOptim is another blackbox optimisation package.\nJuMP is focused on mathematical optimisation for differentiable objective functions.","category":"page"},{"location":"references.html#Python","page":"References & related links","title":"Python","text":"","category":"section"},{"location":"references.html","page":"References & related links","title":"References & related links","text":"DEAP is a somewhat outdated evolutionary playground for Python 2.\nPygmo is a fully-fledged optimisation suite from the European Space Agency.","category":"page"},{"location":"references.html#References","page":"References & related links","title":"References","text":"","category":"section"},{"location":"references.html","page":"References & related links","title":"References & related links","text":"[1] Eiben, A.E. and Smith, J.E. 2015. Introduction to Evolutionary Computing. Springer.\n[2] Kochenderfer, M.J. and Wheeler, T.A. 2019. Algorithms for optimization. Mit Press.\n[3] Simon, D. 2013. Evolutionary Optimization Algorithms. John Wiley & Sons.\n[4] Surjanovic, S. & Bingham, D. (2013). Virtual Library of Simulation Experiments: Test Functions and Datasets.","category":"page"},{"location":"man/mutation.html#Mutation-operators","page":"Mutation operators","title":"Mutation operators","text":"","category":"section"},{"location":"man/mutation.html","page":"Mutation operators","title":"Mutation operators","text":"Mutation operators (a.k.a. mutators) are derived from the EvoLP.MutationMethod abstract type, and some of them have parameters to control how the mutation is performed. Mutation methods are dependent on both the data contained in an individual and its representation.","category":"page"},{"location":"man/mutation.html","page":"Mutation operators","title":"Mutation operators","text":"Currently, mutation is only implemented for vector individuals.","category":"page"},{"location":"man/mutation.html#Selecting-a-mutation-operator","page":"Mutation operators","title":"Selecting a mutation operator","text":"","category":"section"},{"location":"man/mutation.html","page":"Mutation operators","title":"Mutation operators","text":"EvoLP provides many built-in mutators.","category":"page"},{"location":"man/mutation.html#For-binary-vectors","page":"Mutation operators","title":"For binary vectors","text":"","category":"section"},{"location":"man/mutation.html","page":"Mutation operators","title":"Mutation operators","text":"BitwiseMutation","category":"page"},{"location":"man/mutation.html#EvoLP.BitwiseMutation","page":"Mutation operators","title":"EvoLP.BitwiseMutation","text":"Bitwise mutation with probability Î» of flipping each bit.\n\n\n\n\n\n","category":"type"},{"location":"man/mutation.html#For-continuous-vectors","page":"Mutation operators","title":"For continuous vectors","text":"","category":"section"},{"location":"man/mutation.html","page":"Mutation operators","title":"Mutation operators","text":"GaussianMutation","category":"page"},{"location":"man/mutation.html#EvoLP.GaussianMutation","page":"Mutation operators","title":"EvoLP.GaussianMutation","text":"Gaussian mutation with standard deviation Ï, which should be a real number.\n\n\n\n\n\n","category":"type"},{"location":"man/mutation.html#For-permutation-based-vectors","page":"Mutation operators","title":"For permutation-based vectors","text":"","category":"section"},{"location":"man/mutation.html","page":"Mutation operators","title":"Mutation operators","text":"SwapMutation\nInsertMutation\nScrambleMutation\nInversionMutation","category":"page"},{"location":"man/mutation.html#EvoLP.SwapMutation","page":"Mutation operators","title":"EvoLP.SwapMutation","text":"Swap mutation for permutation-based individuals.\n\n\n\n\n\n","category":"type"},{"location":"man/mutation.html#EvoLP.InsertMutation","page":"Mutation operators","title":"EvoLP.InsertMutation","text":"Insert mutation for permutation-based individuals.\n\n\n\n\n\n","category":"type"},{"location":"man/mutation.html#EvoLP.ScrambleMutation","page":"Mutation operators","title":"EvoLP.ScrambleMutation","text":"Scramble mutation for permutation-based individuals.\n\n\n\n\n\n","category":"type"},{"location":"man/mutation.html#EvoLP.InversionMutation","page":"Mutation operators","title":"EvoLP.InversionMutation","text":"Inversion mutation for permutation-based individuals.\n\n\n\n\n\n","category":"type"},{"location":"man/mutation.html#Performing-the-mutation","page":"Mutation operators","title":"Performing the mutation","text":"","category":"section"},{"location":"man/mutation.html","page":"Mutation operators","title":"Mutation operators","text":"After \"instantiating\" a mutation method, you can use mutate on a single individual ind. All operators return a copy, and in the process no individual is modified.","category":"page"},{"location":"man/mutation.html","page":"Mutation operators","title":"Mutation operators","text":"mutate","category":"page"},{"location":"man/mutation.html#EvoLP.mutate","page":"Mutation operators","title":"EvoLP.mutate","text":"mutate(M::BitwiseMutation, ind)\n\nRandomly flips each bit with a probability Î».\n\n\n\n\n\nmutate(M::GaussianMutation, ind)\n\nRandomly add Gaussian noise to the ind candidate solution, with a standard deviation of Ï.\n\n\n\n\n\nmutate(::SwapMutation, ind)\n\nRandomly swap the position of two alleles in the ind candidate solution.\n\n\n\n\n\nmutate(::InsertMutation, ind)\n\nRandomly choose two positions a and b from ind, insert at a+1 the element at position b`, and shift the rest of the elements.\n\n\n\n\n\nmutate(::ScrambleMutation, ind)\n\nRandomly scramble the subsequence between two random points in ind.\n\n\n\n\n\nmutate(::InversionMutation, ind)\n\nInvert the subsequence between two random points in ind.\n\n\n\n\n\n","category":"function"},{"location":"tuto/ga_rosenbrock.html#Generational-GA-for-continuous-optimisation","page":"GA for continuous optimisation","title":"Generational GA for continuous optimisation","text":"","category":"section"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"This tutorial details how to use the built-in Genetic Algorithm (GA) on a continuous test function.","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"We start by importing EvoLP. We will compute some statistics using the Logbook so we need some additional modules as well:","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"using Statistics\nusing EvoLP\nusing OrderedCollections","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"For this example we will use the Rosenbrock function, which is already included as a benchmark in EvoLP. We can look at the documentation like so:","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"@doc rosenbrock","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"rosenbrock(x; a=1, b=5)","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"Rosenbrock benchmark function. With a=1 and b=5, minimum is at f(a a^2) = 0f(x) = (a - x_1)^2 + b(x_2 - x_1^2)^2","category":"page"},{"location":"tuto/ga_rosenbrock.html#Implementing-the-solution","page":"GA for continuous optimisation","title":"Implementing the solution","text":"","category":"section"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"Let's start creating the population. We can  use the normal_rand_vector_pop generator, which uses a normal distribution for initialisation:","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"@doc normal_rand_vector_pop","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"normal_rand_vector_pop(n, Î¼, Î£; rng=Random.GLOBAL_RNG)","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"Generate a population of n vector individuals using a normal distribution with means Î¼ and covariance Î£. Î¼ expects a vector of length l (i.e. length of an individual) while Î£ expects an l x l matrix of covariances.","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"The rosenbrock in our case is 2D, so we need a vector of 2 means, and a matrix of 2x2 covariances:","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"pop_size = 50\npopulation = normal_rand_vector_pop(pop_size, [0, 0], [1 0; 0 1])\nfirst(population, 3)","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"3-element Vector{Vector{Float64}}:\n    [-1.6427111696272696, 0.5882958618620507]\n    [-1.0327502018102739, -0.12553291195289634]\n    [0.16879891668759264, -0.41216354050954684]","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"In a GA, we have selection, crossover and mutation.","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"We can easily set up these operators using the built-ins provided by EvoLP. Let's use rank based selection and interpolation crossover with 0.5 as the scaling factor:","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"@doc InterpolationCrossover","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"Interpolation crossover with scaling parameter Î».","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"S = RankBasedSelectionGenerational()\nC = InterpolationCrossover(0.5)","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"InterpolationCrossover(0.5)","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"For mutation, we can use Gaussian noise:","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"@doc GaussianMutation","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"Gaussian mutation with standard deviation Ï, which should be a real number.","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"M = GaussianMutation(0.5)","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"GaussianMutation(0.5)","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"Now we can set up the Logbook to record statistics about our run:","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"statnames = [\"mean_eval\", \"max_f\", \"min_f\", \"median_f\"]\nfns = [mean, maximum, minimum, median]\nthedict = LittleDict(statnames, fns)\nthelogger = Logbook(thedict)","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"Logbook(LittleDict{AbstractString, Function, Vector{AbstractString}, Vector{Function}}(\"mean_eval\" => Statistics.mean, \"max_f\" => maximum, \"min_f\" => minimum, \"median_f\" => Statistics.median), NamedTuple{(:mean_eval, :max_f, :min_f, :median_f)}[])","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"And now we're ready to use the GA built-in algorithm:","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"@doc GA","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"GA(f::Function, pop, k_max, S, C, M)\nGA(logbook::Logbook, f::Function, pop, k_max, S, C, M)","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"Generational Genetic Algorithm.Argumentsf: Objective function to minimise\npop: Populationâa list of individuals.\nk_max: maximum iterations\nS::SelectionMethod: a selection method. See selection.\nC::CrossoverMethod: a crossover method. See crossover.\nM::MutationMethod: a mutation method. See mutation.Returns a Result.","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"result = GA(thelogger, rosenbrock, population, 300, S, C, M);","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"The output was suppressed so that we can analyse each part of the result separately using functions instead:","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"@show optimum(result)\n\n@show optimizer(result)\n\n@show f_calls(result)\n\nthelogger.records[end]","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"optimum(result) = 0.0015029528354023858\noptimizer(result) = [1.0367119356341026, 1.0803427525882299]\nf_calls(result) = 50050\n\n(mean_eval = 3.7839504926952294, max_f = 22.281919411164413, min_f = 0.0015029528354023858, median_f = 2.429775485243721)","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"The records in the Logbook are NamedTuples. This makes it easier to export and analyse using DataFrames, for example:","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"using DataFrames\nDataFrame(thelogger.records)","category":"page"},{"location":"tuto/ga_rosenbrock.html","page":"GA for continuous optimisation","title":"GA for continuous optimisation","text":"500Ã4 DataFrame\n Row â mean_eval  max_f     min_f        median_f \n     â Float64    Float64   Float64      Float64  \nââââââ¼ââââââââââââââââââââââââââââââââââââââââââââ\n   1 â   9.89648  134.066   0.149169      3.6715\n   2 â   5.73033   40.1663  0.134373      2.94368\n   3 â   4.65904   18.9003  0.181144      3.22389\n   4 â   4.34055   52.1745  0.0813748     2.14014\n   5 â   5.1239    42.4315  0.119411      2.83591\n   6 â   3.70733   37.285   0.0413168     2.17732\n   7 â   4.84669   66.9539  0.00445092    2.52908\n   8 â   3.87748   26.8901  0.345194      1.75084\n  â®  â     â®         â®           â®          â®","category":"page"},{"location":"man/results.html#Reporting-results","page":"Reporting results","title":"Reporting results","text":"","category":"section"},{"location":"man/results.html","page":"Reporting results","title":"Reporting results","text":"EvoLP provides a type for reporting results that you can use as the return vale of an algorithm. The type has different data fields conveniently stored in a single variable, which allows for further inspection if desired (for example for post-mortem visualisation and analysis.)","category":"page"},{"location":"man/results.html","page":"Reporting results","title":"Reporting results","text":"Result","category":"page"},{"location":"man/results.html#EvoLP.Result","page":"Reporting results","title":"EvoLP.Result","text":"A type for reporting results of an algorithm: the optimum f(x^*), the optimizer x^*, the population, the number of iterations and the number of function calls.\n\n\n\n\n\n","category":"type"},{"location":"man/results.html","page":"Reporting results","title":"Reporting results","text":"Some getter functions are also included to obtain specific information about the result.","category":"page"},{"location":"man/results.html","page":"Reporting results","title":"Reporting results","text":"optimum\noptimizer\npopulation\niterations\nf_calls","category":"page"},{"location":"man/results.html#EvoLP.optimum","page":"Reporting results","title":"EvoLP.optimum","text":"optimum(result)\n\nReturns evaluation of solution found f(x^*).\n\n\n\n\n\n","category":"function"},{"location":"man/results.html#EvoLP.optimizer","page":"Reporting results","title":"EvoLP.optimizer","text":"optimizer(result)\n\nReturns solution found x^*.\n\n\n\n\n\n","category":"function"},{"location":"man/results.html#EvoLP.population","page":"Reporting results","title":"EvoLP.population","text":"population(res)\n\nReturns the resulting population of the algorithm.\n\n\n\n\n\n","category":"function"},{"location":"man/results.html#EvoLP.iterations","page":"Reporting results","title":"EvoLP.iterations","text":"iterations(res)\n\nReturns the number of iterations of a result.\n\n\n\n\n\n","category":"function"},{"location":"man/results.html#EvoLP.f_calls","page":"Reporting results","title":"EvoLP.f_calls","text":"f_calls(res)\n\nReturns number of function evaluation calls of a result.\n\n\n\n\n\n","category":"function"},{"location":"man/results.html","page":"Reporting results","title":"Reporting results","text":"All built-in algorithms in EvoLP use the Result as their return value.","category":"page"},{"location":"man/quickstart.html#Quick-start","page":"Workflow","title":"Quick start","text":"","category":"section"},{"location":"man/quickstart.html","page":"Workflow","title":"Workflow","text":"EvoLP was designed as a playground, where each block is a reusable computation pattern that you can use to quickly set up your own algorithms and workflows.","category":"page"},{"location":"man/quickstart.html","page":"Workflow","title":"Workflow","text":"You can find some useful tutorials in the navigation bar. These examples are also available in the repository as Jupyter Notebooks. The tutorial on the 8 queens problem details how to incorporate a custom algorithm into the workflow. If you want to use custom blocks, you can do that too.","category":"page"},{"location":"man/quickstart.html#Installation-Guide","page":"Workflow","title":"Installation Guide","text":"","category":"section"},{"location":"man/quickstart.html#Install-Julia","page":"Workflow","title":"Install Julia","text":"","category":"section"},{"location":"man/quickstart.html","page":"Workflow","title":"Workflow","text":"EvoLP is a package for Julia. To use EvoLP, download and install the latest version of Julia first.","category":"page"},{"location":"man/quickstart.html#Install-EvoLP","page":"Workflow","title":"Install EvoLP","text":"","category":"section"},{"location":"man/quickstart.html","page":"Workflow","title":"Workflow","text":"You can install EvoLP from the Julia REPL using the built-in package manager:","category":"page"},{"location":"man/quickstart.html","page":"Workflow","title":"Workflow","text":"julia> import Pkg\njulia> Pkg.add(\"EvoLP\")","category":"page"},{"location":"man/quickstart.html","page":"Workflow","title":"Workflow","text":"Alternatively, you can enter Pkg mode by pressing the ] key and then add EvoLP like so:","category":"page"},{"location":"man/quickstart.html","page":"Workflow","title":"Workflow","text":"julia> ] # upon typing ], the prompt changes (in place) to: pkg>\npkg> add EvoLP","category":"page"},{"location":"man/quickstart.html","page":"Workflow","title":"Workflow","text":"Once EvoLP is installed, you can use all the building blocks by importing/using it at the top of your code:","category":"page"},{"location":"man/quickstart.html","page":"Workflow","title":"Workflow","text":"using EvoLP\n\n# your code here","category":"page"},{"location":"man/quickstart.html#The-general-workflow","page":"Workflow","title":"The general  workflow","text":"","category":"section"},{"location":"man/quickstart.html","page":"Workflow","title":"Workflow","text":"A common workflow in EvoLP is somewhat similar to this:","category":"page"},{"location":"man/quickstart.html","page":"Workflow","title":"Workflow","text":"Use a generator for initialising your population.\nCode your objective or use a test benchmark function.\nDepending on your objective function and individual representation, choose appropriate selectors, recombinators and mutators.\nUse a built-in algorithm or code your own. Roughly:\nEvaluate your population.\nUse select and cross to generate new solutions.\nStochastically alter new solutions using mutate.\nEvaluate the new population members and select the survivors.\nOptionally compute statistic and log them in the Logbook.\nReturn the results.","category":"page"},{"location":"tuto/pso_michalewicz.html#Using-PSO-to-minimise-the-Michalewicz-function","page":"PSO for continuous optimisation","title":"Using PSO to minimise the Michalewicz function","text":"","category":"section"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"This tutorial showcases how to use the built-in Particle Swarm Optimisation (PSO) algorithm for finding the minimum in a continuos setting.","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"We start by importing our necessary modules","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"using EvoLP\nusing Statistics\nusing OrderedCollections","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"For this example, we will use the Michalewicz function, which is a test function included in EvoLP:","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"@doc michalewicz","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"michalewicz(x; m=10)","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"The Michalewicz function is a d-dimensional function with several steep valleys, where m controls the steepness. m is usually set at 10. For 2 dimensions, x^* = 220 157, with f(x^*) = -18011.f(x) = -sum_i=1^dsin(x_i) sin^2mleft(fracix_i^2piright)","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"In this case we will use d=2 and m=10, which are the default values implemented.","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"In PSO, we use particles. Each particle has a position and a velocity, and remembers the best position the whole swarm has visited. We can create a population of particles in multiple ways, but EvoLP provides 2 particle generators with random positions: either uniform or following a normal distribution.","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"Let's use the normal generator:particle generators","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"@doc normal_rand_particle_pop","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"normal_rand_particle_pop(n, Î¼, Î£; rng=Random.GLOBAL_RNG)","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"Generate a population of n Particle using a normal distribution with means Î¼ and covarianceÎ£. Î¼ expects a vector of length l (i.e. number of dimensions) while Î£ expects an l x l matrix of covariances.","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"Since we are using the 2-dimensional version of the function, we need to provide a vector of 2 means and a 2 \\times 2 matrix of covariances:","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"population = normal_rand_particle_pop(50, [0, 0], [1 0; 0 1])\nfirst(population, 3)","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"3-element Vector{Particle}:\n    Particle([-0.22703948747578281, 1.7689889087227626], [0.0, 0.0], [-0.22703948747578281, 1.7689889087227626])\n    Particle([0.9523372333139276, 1.8452380648469366], [0.0, 0.0], [0.9523372333139276, 1.8452380648469366])\n    Particle([-1.2560899837782407, 0.15303679468484374], [0.0, 0.0], [-1.2560899837782407, 0.15303679468484374])","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"We can use the Logbook to save information about each iteration of the run. Let's save the average, median and best fitness:","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"statnames = [\"avg_fit\", \"median_fit\", \"best_fit\"]\ncallables = [mean, median, minimum]\n\nthedict = LittleDict(statnames, callables)\nlogbook = Logbook(thedict)","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"Logbook(LittleDict{AbstractString, Function, Vector{AbstractString}, Vector{Function}}(\"avg_fit\" => Statistics.mean, \"median_fit\" => Statistics.median, \"best_fit\" => minimum), NamedTuple{(:avg_fit, :median_fit, :best_fit)}[])","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"Now we can use the built-in PSO algorithm:","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"@doc PSO","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"PSO(f::Function, population::Vector{Particle}, k_max::Integer; w=1, c1=1, c2=1)\nPSO(logger::Logbook, f::Function, population::Vector{Particle}, k_max::Integer; w=1, c1=1, c2=1)","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"Argumentsf::Function: Objective function to minimise\npopulation: Populationâa list of Particle individuals\nk_max: maximum iterations\nw: Inertia weight. Optional, by default 1.\nc1: Cognitive coefficient (my position). Optional, by default 1\nc2: Social coefficient (swarm position). Optional, by default 1Returns a Result.","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"Let's use the default parameters, and 30 iterations:","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"results = PSO(logbook, michalewicz, population, 30);","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"The output was suppressed so that we can analyse each part of the result separately using the Result functions:","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"@show optimum(results)\n@show optimizer(results)\n@show iterations(results)\n@show f_calls(results)","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"optimum(results) = -1.7945699649685944\noptimizer(results) = Particle([2.4587719347604904, 1.5710645311634195], [-0.3065425967254033, 3.75884997817273e-5], [2.1824224667308583, 1.5710530344414129])\niterations(results) = 30\nf_calls(results) = 4601","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"We can also take a look at the logbook's records and see how the calculated statistics changed throughout the run:","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"for (i, I) in enumerate(logbook.records)\n    print(\"it: $(i) with best_pos: $(I[3]) and avg_pos: $(I[1]) \\n\")\nend","category":"page"},{"location":"tuto/pso_michalewicz.html","page":"PSO for continuous optimisation","title":"PSO for continuous optimisation","text":"it: 1 with best_pos: -0.6906794768370129 and avg_pos: -0.005754793636862157 \nit: 2 with best_pos: -0.9897012274595496 and avg_pos: -0.17476488948373003 \nit: 3 with best_pos: -1.102946135488689 and avg_pos: -0.2783471388805291 \nit: 4 with best_pos: -0.968940921732735 and avg_pos: -0.3095523155518831 \nit: 5 with best_pos: -1.472368499905572 and avg_pos: -0.3379717198952197 \nit: 6 with best_pos: -1.3055867468693856 and avg_pos: -0.3258715803445814 \nit: 7 with best_pos: -1.3634607463646478 and avg_pos: -0.45466359334515916 \nit: 8 with best_pos: -1.6705825784286839 and avg_pos: -0.6029634734635035 \nit: 9 with best_pos: -1.5345866019317895 and avg_pos: -0.5501090751560626 \nit: 10 with best_pos: -1.7212146343892145 and avg_pos: -0.5773626889249354 \nit: 11 with best_pos: -1.779247279246615 and avg_pos: -0.6533233522934709 \nit: 12 with best_pos: -1.7838823541946531 and avg_pos: -0.6378969618098259 \nit: 13 with best_pos: -1.7931685047158967 and avg_pos: -0.6128555872381239 \nit: 14 with best_pos: -1.7602231973069682 and avg_pos: -0.6399893054000261 \nit: 15 with best_pos: -1.7903696633328317 and avg_pos: -0.5750118483927428 \nit: 16 with best_pos: -1.7898716807412165 and avg_pos: -0.5954660432077975 \nit: 17 with best_pos: -1.785632556103051 and avg_pos: -0.6282199097964665 \nit: 18 with best_pos: -1.793412068667957 and avg_pos: -0.5967425923776992 \nit: 19 with best_pos: -1.7945699649685944 and avg_pos: -0.5916369173134188 \nit: 20 with best_pos: -1.7523847497822869 and avg_pos: -0.6651822602448447 \nit: 21 with best_pos: -1.7851864041976486 and avg_pos: -0.5823099403323408 \nit: 22 with best_pos: -1.7838001095222875 and avg_pos: -0.6533675831853937 \nit: 23 with best_pos: -1.7739653477376558 and avg_pos: -0.6095419482154109 \nit: 24 with best_pos: -1.7818070429845911 and avg_pos: -0.6334580923663595 \nit: 25 with best_pos: -1.7849119381216694 and avg_pos: -0.5762643811160446 \nit: 26 with best_pos: -1.7938521468057878 and avg_pos: -0.684789042512983 \nit: 27 with best_pos: -1.7808066875854238 and avg_pos: -0.5577077719919309 \nit: 28 with best_pos: -1.7608941215987302 and avg_pos: -0.6351975353921133 \nit: 29 with best_pos: -1.7829383704900754 and avg_pos: -0.5261806929819258 \nit: 30 with best_pos: -1.7905107361608266 and avg_pos: -0.575240903673051","category":"page"},{"location":"man/extending.html#Creating-your-own-blocks","page":"Custom operators","title":"Creating your own blocks","text":"","category":"section"},{"location":"man/extending.html","page":"Custom operators","title":"Custom operators","text":"If you want to experiment with new building blocks, you can create your own by using the abstract block types as a supertype of your own mutators, selectors and crossover methods. These abstract blocks are the following:","category":"page"},{"location":"man/extending.html","page":"Custom operators","title":"Custom operators","text":"Modules = [EvoLP]\nPublic = false\nOrder = [:type]","category":"page"},{"location":"man/extending.html#EvoLP.CrossoverMethod","page":"Custom operators","title":"EvoLP.CrossoverMethod","text":"Abstract CrossoverMethod.\n\n\n\n\n\n","category":"type"},{"location":"man/extending.html#EvoLP.MutationMethod","page":"Custom operators","title":"EvoLP.MutationMethod","text":"Abstract MutationMethod.\n\n\n\n\n\n","category":"type"},{"location":"man/extending.html#EvoLP.SelectionMethod","page":"Custom operators","title":"EvoLP.SelectionMethod","text":"Abstract SelectionMethod.\n\n\n\n\n\n","category":"type"},{"location":"man/extending.html","page":"Custom operators","title":"Custom operators","text":"These abstract types are not exported in EvoLP, which means that you will not see them if you used using EvoLP in your code. You need to access them directly, by writing EvoLP.<theabstractblock>.","category":"page"},{"location":"man/extending.html","page":"Custom operators","title":"Custom operators","text":"Once you have your own type, you need to explicitly code how the block should operate. This is done by creating a new function: select, cross or mutate, depending on what your abstract supertype is.","category":"page"},{"location":"man/extending.html","page":"Custom operators","title":"Custom operators","text":"After that, you can use the new blocks in your algorithms like any of the other built-in blocks.","category":"page"},{"location":"man/extending.html#A-hypothetical-example","page":"Custom operators","title":"A hypothetical example","text":"","category":"section"},{"location":"man/extending.html","page":"Custom operators","title":"Custom operators","text":"You can use the corresponding AbstractType to create a new mutation method called MyCrazyMutation like so:","category":"page"},{"location":"man/extending.html","page":"Custom operators","title":"Custom operators","text":"struct MyCrazyMutation <: EvoLP.MutationMethod\n    param1\n    param2\n    param3\nend","category":"page"},{"location":"man/extending.html","page":"Custom operators","title":"Custom operators","text":"Then, we will create a new function mutate which will look something like the following:","category":"page"},{"location":"man/extending.html","page":"Custom operators","title":"Custom operators","text":"function mutate(M::MyCrazyMutation, ind; rng=Random.GLOBAL_RNG)\n    mutant = deepcopy(ind)\n    if rand(rng) < param3\n        mutant[1] = mutant[1] + M.param1\n        mutant[2] = mutant[2] - M.param2\n    end\n\n    return mutant\nend","category":"page"},{"location":"man/extending.html","page":"Custom operators","title":"Custom operators","text":"This MyCrazyMutation method will then operate on a hypothetical 2-dimensional individual ind, and will change its first dimension by its param1, and the second dimension using param2 if a random number is less than its param3.","category":"page"},{"location":"man/extending.html","page":"Custom operators","title":"Custom operators","text":"Then, you can use it in your algorithms as if it was any other block. Here is a fake snippet for illustration purposes:","category":"page"},{"location":"man/extending.html","page":"Custom operators","title":"Custom operators","text":"function myalgorithm(...)\n    M = MyCrazyMutation(p1, p2, p3)\n    ...\n    mutate(M, ind)\n    ...\nend","category":"page"},{"location":"man/extending.html#A-word-about-randomisation","page":"Custom operators","title":"A word about randomisation","text":"","category":"section"},{"location":"man/extending.html","page":"Custom operators","title":"Custom operators","text":"If using random numbers (for example in crossover or mutation operators) it is always a good idea to pass to your function a random number generator instance. In this way, your code can be both used for unit testing as well as for constructing shareable examples that are reproducible for the sake of science.","category":"page"},{"location":"man/benchmarks.html#Benchmark-functions","page":"Benchmark functions","title":"Benchmark functions","text":"","category":"section"},{"location":"man/benchmarks.html","page":"Benchmark functions","title":"Benchmark functions","text":"EvoLP includes some test functions to benchmark your algorithms. Unless otherwise specified, every function is of the form f(x).","category":"page"},{"location":"man/benchmarks.html#Pseudo-boolean-functions","page":"Benchmark functions","title":"Pseudo boolean functions","text":"","category":"section"},{"location":"man/benchmarks.html","page":"Benchmark functions","title":"Benchmark functions","text":"onemax\nleadingones\njumpk","category":"page"},{"location":"man/benchmarks.html#EvoLP.onemax","page":"Benchmark functions","title":"EvoLP.onemax","text":"The OneMax function returns the sum of the individual. For an individual of length n, maximum is achieved with n ones.\n\ntextOneMax(mathbfx) = sum_i=1^n x_i\n\n\n\n\n\n","category":"function"},{"location":"man/benchmarks.html#EvoLP.leadingones","page":"Benchmark functions","title":"EvoLP.leadingones","text":"The LeadingOnes function returns the number of uninterrupted ones from the start of the chromosome. The maximum is achieved with n ones, but the landscape is a bit more difficult to traverse.\n\ntextLO(mathbfx) = sum_i=1^n prod_j^i x_j\n\n\n\n\n\n","category":"function"},{"location":"man/benchmarks.html#EvoLP.jumpk","page":"Benchmark functions","title":"EvoLP.jumpk","text":"jumpk(x; k=6)\n\nThe JumpK function is a modification of the onemax function, with a valley of size k right before the maximum. The only way for a hill climber to reach the maximum is with a perfect flip of k bits, which is considered extremely difficult.\n\ntextJUMP_k(x) = begincases\nlVertxrVert_1  quad textif  lVert x rVert_1 in 0n-k cup n\n-lVert x rVert_1  quad textotherwise\nendcases\n\nwhere lVert x rVert_1 = sum_i=1^n x_i is the number of 1-bits in x in 0 1^n.\n\n\n\n\n\n","category":"function"},{"location":"man/benchmarks.html#Continuous-functions","page":"Benchmark functions","title":"Continuous functions","text":"","category":"section"},{"location":"man/benchmarks.html","page":"Benchmark functions","title":"Benchmark functions","text":"Continuous functions implementations were taken from Kochenderfer, M.J. and Wheeler, T.A. (2019). Most of these can be visualised in Surjanovic, S. & Bingham, D. (2013).","category":"page"},{"location":"man/benchmarks.html","page":"Benchmark functions","title":"Benchmark functions","text":"ackley\nbooth\nbranin\ncircle\nflower\nmichalewicz\nrosenbrock\nwheeler","category":"page"},{"location":"man/benchmarks.html#EvoLP.ackley","page":"Benchmark functions","title":"EvoLP.ackley","text":"ackley(x; a=20, b=0.2, c=2Ï)\n\nAckley's benchmark function. Global minimum is at the origin, with optimal value of 0. Parameters are typically a=20, b=02, and c=2pi.\n\nf(x) = -a expleft(-bsqrtfrac1d sum_i=1^d x_i^2right)\n- expleft(frac1d sum_i=1d cos (cx_i) right) + a + exp(1)\n\n\n\n\n\n","category":"function"},{"location":"man/benchmarks.html#EvoLP.booth","page":"Benchmark functions","title":"EvoLP.booth","text":"The Booth function is a 2-dimensional quadratic function with global minimum x^* = 1 3 and optimal value f(x^*) = 0.\n\nf(x) = (x_1 + 2x_2 - 7)^2 + (2 x_1 + x_2 - 5)^2\n\n\n\n\n\n","category":"function"},{"location":"man/benchmarks.html#EvoLP.branin","page":"Benchmark functions","title":"EvoLP.branin","text":"branin(x; a=1, b=5.1/(4Ï^2), c=5/Ï, r=6, s=10, t=1/(8Ï))\n\nThe Branin (a.k.a. Branin-Hoo) function has six optional parameters, and features multiple global minima. Some of them are at x^* = -pi 12275, x^* = pi 2275, x^* = 3pi 2475 and x^* = 5pi 12875, with f(x^*) approx 0397887.\n\nf(x) = a(x_2 - bx_1^2 + cx_1 - r)^2 + s(1 - t)cos(x_1) + s\n\n\n\n\n\n","category":"function"},{"location":"man/benchmarks.html#EvoLP.circle","page":"Benchmark functions","title":"EvoLP.circle","text":"The circle function is a multiobjective test function, given by\n\nf(x) = beginbmatrix\n        1 - rcos(theta) \n        1 - rsin(theta)\n        endbmatrix\n\nwhere theta=x_1 and r is obtained by\n\nr = frac12 + frac12 left(frac2x_21+x_2^2right)\n\n\n\n\n\n","category":"function"},{"location":"man/benchmarks.html#EvoLP.flower","page":"Benchmark functions","title":"EvoLP.flower","text":"flower(x; a=1, b=1, c=4)\n\nThe flower function is a two-dimensional test function with flower-like contour lines coming out from the origin. Typically, optional parameters are set at a=1, b=1 and c=4. The function is minimised near the origin, although it does not have a global minimum due to atan bein undefined at 0 0.\n\nf(x) = alVertmathbbxrVert + b sin(carctan(x_2 x_1))\n\n\n\n\n\n","category":"function"},{"location":"man/benchmarks.html#EvoLP.michalewicz","page":"Benchmark functions","title":"EvoLP.michalewicz","text":"michalewicz(x; m=10)\n\nThe Michalewicz function is a d-dimensional function with several steep valleys, where m controls the steepness. m is usually set at 10. For 2 dimensions, x^* = 220 157, with f(x^*) = -18011.\n\nf(x) = -sum_i=1^dsin(x_i) sin^2mleft(fracix_i^2piright)\n\n\n\n\n\n","category":"function"},{"location":"man/benchmarks.html#EvoLP.rosenbrock","page":"Benchmark functions","title":"EvoLP.rosenbrock","text":"rosenbrock(x; a=1, b=5)\n\nRosenbrock benchmark function. With a=1 and b=5, minimum is at f(a a^2) = 0\n\nf(x) = (a - x_1)^2 + b(x_2 - x_1^2)^2\n\n\n\n\n\n","category":"function"},{"location":"man/benchmarks.html#EvoLP.wheeler","page":"Benchmark functions","title":"EvoLP.wheeler","text":"wheeler(x, a=1.5)\n\nThe Wheeler's ridge is a 2-d function with a single global minimum in a curved peak. With a (by default at 1.5) x^* = 1 15, with f(x^*) = -1.\n\nf(x) = - exp(- (x_1 x_2 - a)^2 - (x_2 - a)^2 )\n\n\n\n\n\n","category":"function"},{"location":"lib/types.html#Types-in-EvoLP","page":"Types","title":"Types in EvoLP","text":"","category":"section"},{"location":"lib/types.html","page":"Types","title":"Types","text":"Modules = [EvoLP]\nOrder = [:type]","category":"page"},{"location":"man/generators.html#Population-Generators","page":"Population generators","title":"Population Generators","text":"","category":"section"},{"location":"man/generators.html","page":"Population generators","title":"Population generators","text":"To initialise the population, a number of random generators are provided.","category":"page"},{"location":"man/generators.html#Vector-based-populations","page":"Population generators","title":"Vector-based populations","text":"","category":"section"},{"location":"man/generators.html","page":"Population generators","title":"Population generators","text":"For EAs and GAs.","category":"page"},{"location":"man/generators.html#Discrete-domains","page":"Population generators","title":"Discrete domains","text":"","category":"section"},{"location":"man/generators.html","page":"Population generators","title":"Population generators","text":"binary_vector_pop\npermutation_vector_pop","category":"page"},{"location":"man/generators.html#EvoLP.binary_vector_pop","page":"Population generators","title":"EvoLP.binary_vector_pop","text":"binary_vector_pop(n, l; rng=Random.GLOBAL_RNG)\n\nGenerate a population of n vector binary individuals, each of length l.\n\nExamples\n\njulia> using EvoLP\n\njulia> binary_vector_pop(2, 5)\n2-element Vector{BitVector}:\n [1, 0, 1, 1, 0]\n [0, 1, 0, 0, 0]\n\n\n\n\n\n","category":"function"},{"location":"man/generators.html#EvoLP.permutation_vector_pop","page":"Population generators","title":"EvoLP.permutation_vector_pop","text":"permutation_vector_pop(n, d, pool; replacement=false, rng=Random.GLOBAL_RNG)\n\nGenerate a population of n permutation vector individuals, of size d and with values sampled from pool. Usually d would be equal to length(pool).\n\nSampling is without replacement by default (generating permutations if pool is a set). When replacement=true then it generates combinations of (possibly) repeated values.\n\nExamples\n\njulia> permutation_vector_pop(1, 8, 1:8)\n1-element Vector{Vector{Int64}}:\n [7, 3, 8, 1, 5, 6, 4, 2]\n\njulia> permutation_vector_pop(2, 5, [\"a\", \"b\", \"c\", \"d\", \"e\"]; replacement=false)\n2-element Vector{Vector{String}}:\n [\"e\", \"b\", \"c\", \"d\", \"a\"]\n [\"b\", \"d\", \"a\", \"e\", \"c\"]\n\n\n\n\n\n","category":"function"},{"location":"man/generators.html#Continuous-domains","page":"Population generators","title":"Continuous domains","text":"","category":"section"},{"location":"man/generators.html","page":"Population generators","title":"Population generators","text":"normal_rand_vector_pop\nunif_rand_vector_pop","category":"page"},{"location":"man/generators.html#EvoLP.normal_rand_vector_pop","page":"Population generators","title":"EvoLP.normal_rand_vector_pop","text":"normal_rand_vector_pop(n, Î¼, Î£; rng=Random.GLOBAL_RNG)\n\nGenerate a population of n vector individuals using a normal distribution with means Î¼ and covariance Î£.\n\nÎ¼ expects a vector of length l (i.e. length of an individual) while Î£ expects an l x l matrix of covariances.\n\nExamples\n\njulia> normal_rand_vector_pop(3, [0, 0], [1 0; 0 1])\n3-element Vector{Vector{Float64}}:\n [-0.15290525182234904, 0.8715880371871617]\n [-1.1283800329864322, -0.9256584563613383]\n [-0.5384758126777555, -0.8141702145510666]\n\n\n\n\n\n","category":"function"},{"location":"man/generators.html#EvoLP.unif_rand_vector_pop","page":"Population generators","title":"EvoLP.unif_rand_vector_pop","text":"unif_rand_vector_pop(n, lb, ub; rng=Random.GLOBAL_RNG)\n\nGenerate a population of n vector individuals using a uniformly random distribution between lower bounds lb and upper bounds ub.\n\nBoth lb and ub must be arrays of the same dimensions.\n\nExamples\n\njulia> unif_rand_vector_pop(3, [-1, -1], [1, 1])\n3-element Vector{Vector{Float64}}:\n [-0.16338687344459046, 0.31576097298524064]\n [-0.941510876597899, 0.8219576462978224]\n [-0.377090051761797, -0.28434454028992096]\n\n\n\n\n\n","category":"function"},{"location":"man/generators.html#Particle-based-populations","page":"Population generators","title":"Particle-based populations","text":"","category":"section"},{"location":"man/generators.html","page":"Population generators","title":"Population generators","text":"For particle-swarm optimisation.","category":"page"},{"location":"man/generators.html","page":"Population generators","title":"Population generators","text":"Particle","category":"page"},{"location":"man/generators.html#EvoLP.Particle","page":"Population generators","title":"EvoLP.Particle","text":"A single particle in the swarm, with a position x, a velocity v and the best position it has encountered x_best.\n\n\n\n\n\n","category":"type"},{"location":"man/generators.html","page":"Population generators","title":"Population generators","text":"unif_rand_particle_pop\nnormal_rand_particle_pop","category":"page"},{"location":"man/generators.html#EvoLP.unif_rand_particle_pop","page":"Population generators","title":"EvoLP.unif_rand_particle_pop","text":"unif_rand_particle_pop(n, lb, ub; rng=Random.GLOBAL_RNG)\n\nGenerate a population of n Particle individuals using a uniformly random distribution between lower bounds lb and upper bounds ub.\n\nBoth lb and ub must be arrays of the same dimensions.\n\nExamples\n\njulia> unif_rand_particle_pop(3, [-1, -1], [1, 1])\n3-element Vector{Particle}:\n Particle([0.012771979849810489, 1.5375945897550218], [0, 0], [0.012771979849810489, 1.5375945897550218])\n Particle([1.4615231729898166, 0.7340438556735969], [0, 0], [1.4615231729898166, 0.7340438556735969])\n Particle([0.26586910036555356, 0.22012991705951324], [0, 0], [0.26586910036555356, 0.22012991705951324])\n\n\n\n\n\n","category":"function"},{"location":"man/generators.html#EvoLP.normal_rand_particle_pop","page":"Population generators","title":"EvoLP.normal_rand_particle_pop","text":"normal_rand_particle_pop(n, Î¼, Î£; rng=Random.GLOBAL_RNG)\n\nGenerate a population of n Particle using a normal distribution with means Î¼and covarianceÎ£`.\n\nÎ¼ expects a vector of length l (i.e. number of dimensions) while Î£ expects an l x l matrix of covariances.\n\nExamples\n\njulia> normal_rand_particle_pop(3, [-1, -1], [1 0; 0 1])\n3-element Vector{Particle}:\n Particle([-2.3026589618390214, 0.25907687184121864], [0.0, 0.0], [-2.3026589618390214, 0.25907687184121864])\n Particle([-0.5118786279984703, -0.5948648935657292], [0.0, 0.0], [-0.5118786279984703, -0.5948648935657292])\n Particle([-1.3230210847731094, -1.6234307114658497], [0.0, 0.0], [-1.3230210847731094, -1.6234307114658497])\n\n\n\n\n\n","category":"function"},{"location":"lib/functions.html#Functions-in-EvoLP","page":"Functions","title":"Functions in EvoLP","text":"","category":"section"},{"location":"lib/functions.html","page":"Functions","title":"Functions","text":"Modules = [EvoLP]\nOrder = [:function]","category":"page"},{"location":"man/cross.html#Crossover-operators","page":"Crossover operators","title":"Crossover operators","text":"","category":"section"},{"location":"man/cross.html","page":"Crossover operators","title":"Crossover operators","text":"Crossover operators (a.k.a. recombinators) in EvoLP generate 1 offspring from two parents.","category":"page"},{"location":"man/cross.html","page":"Crossover operators","title":"Crossover operators","text":"All operators are derived from the EvoLP.CrossoverMethod abstract type, and some of them have parameters to control how the recombination is performed. Crossover methods are independent of the data contained in an individual, and are instead dependent on its representation.","category":"page"},{"location":"man/cross.html","page":"Crossover operators","title":"Crossover operators","text":"Currently, crossover is only implemented for vector individuals.","category":"page"},{"location":"man/cross.html#Selecting-a-crossover-operator","page":"Crossover operators","title":"Selecting a crossover operator","text":"","category":"section"},{"location":"man/cross.html","page":"Crossover operators","title":"Crossover operators","text":"EvoLP provides many built-in recombinators.","category":"page"},{"location":"man/cross.html#Representation-independent","page":"Crossover operators","title":"Representation-independent","text":"","category":"section"},{"location":"man/cross.html","page":"Crossover operators","title":"Crossover operators","text":"Single point, two point and uniform crossover operators work on vectors of any numeric type. Using them on permutation-based vectors could generate unfeasible solutions.","category":"page"},{"location":"man/cross.html","page":"Crossover operators","title":"Crossover operators","text":"SinglePointCrossover\nTwoPointCrossover\nUniformCrossover","category":"page"},{"location":"man/cross.html#EvoLP.SinglePointCrossover","page":"Crossover operators","title":"EvoLP.SinglePointCrossover","text":"Single point crossover.\n\n\n\n\n\n","category":"type"},{"location":"man/cross.html#EvoLP.TwoPointCrossover","page":"Crossover operators","title":"EvoLP.TwoPointCrossover","text":"Two point crossover.\n\n\n\n\n\n","category":"type"},{"location":"man/cross.html#EvoLP.UniformCrossover","page":"Crossover operators","title":"EvoLP.UniformCrossover","text":"Uniform crossover.\n\n\n\n\n\n","category":"type"},{"location":"man/cross.html#For-continuous-domains","page":"Crossover operators","title":"For continuous domains","text":"","category":"section"},{"location":"man/cross.html","page":"Crossover operators","title":"Crossover operators","text":"InterpolationCrossover","category":"page"},{"location":"man/cross.html#EvoLP.InterpolationCrossover","page":"Crossover operators","title":"EvoLP.InterpolationCrossover","text":"Interpolation crossover with scaling parameter Î».\n\n\n\n\n\n","category":"type"},{"location":"man/cross.html#For-permutation-representations","page":"Crossover operators","title":"For permutation representations","text":"","category":"section"},{"location":"man/cross.html","page":"Crossover operators","title":"Crossover operators","text":"Order One (OX1) allows for feasibility to be preserved after recombination.","category":"page"},{"location":"man/cross.html","page":"Crossover operators","title":"Crossover operators","text":"OrderOneCrossover","category":"page"},{"location":"man/cross.html#EvoLP.OrderOneCrossover","page":"Crossover operators","title":"EvoLP.OrderOneCrossover","text":"Order 1 crossover (OX1) for permutation-based individuals.\n\n\n\n\n\n","category":"type"},{"location":"man/cross.html#Performing-the-crossover","page":"Crossover operators","title":"Performing the crossover","text":"","category":"section"},{"location":"man/cross.html","page":"Crossover operators","title":"Crossover operators","text":"After \"instantiating\" a crossover method, you can use the cross function. cross operates on two parents a and b to generate a new candidate solution. All operators return a new individual, and in the process no individual is modified.","category":"page"},{"location":"man/cross.html","page":"Crossover operators","title":"Crossover operators","text":"cross","category":"page"},{"location":"man/cross.html#EvoLP.cross","page":"Crossover operators","title":"EvoLP.cross","text":"cross(::SinglePointCrossover, a, b)\n\nSingle point crossover between parents a and b, at a random point in the chromosome.\n\n\n\n\n\ncross(::TwoPointCrossover, a, b)\n\nTwo point crossover between parents a and b, at two random points in the chromosome.\n\n\n\n\n\ncrossover(::UniformCrossover, a, b)\n\nUniform crossover between parents a and b. Each gene of the chromosome is randomly selected from one of the parents.\n\n\n\n\n\ncross(C::InterpolationCrossover, a, b)\n\nLinear Interpolation crossover between parents a and b. The resulting individual is the addition of a scaled version of each of the parents, using C.Î» as a control parameter.\n\n\n\n\n\ncross(::OrderOneCrossover, a, b)\n\nOrder 1 crossover between permutation parents a and b. A substring from a is copied directly to the offspring, and the remaining values are copied in the order they appear in b.\n\n\n\n\n\n","category":"function"},{"location":"man/selection.html#Selection-operators","page":"Selection operators","title":"Selection operators","text":"","category":"section"},{"location":"man/selection.html","page":"Selection operators","title":"Selection operators","text":"Parent selection operators (a.k.a. selectors) in EvoLP are based on fitness and are used to select individuals for crossover. The selectors always return indices so that individuals can be selected from the population later.","category":"page"},{"location":"man/selection.html","page":"Selection operators","title":"Selection operators","text":"These methods come in two variants: steady-state and generational. Steady-state operators return two parent indices, while generational operators return a list of two parent indices for each fitness in the population.","category":"page"},{"location":"man/selection.html","page":"Selection operators","title":"Selection operators","text":"In other words, steady-state variants perform one selection, while generational variants perform n selections.","category":"page"},{"location":"man/selection.html","page":"Selection operators","title":"Selection operators","text":"Regardless of the variant, all operators are derived from the EvoLP.SelectionMethod abstract type and some of them have parameters you can adjust.","category":"page"},{"location":"man/selection.html#Choosing-a-selection-operator","page":"Selection operators","title":"Choosing a selection operator","text":"","category":"section"},{"location":"man/selection.html","page":"Selection operators","title":"Selection operators","text":"EvoLP provides many built-in selectors.","category":"page"},{"location":"man/selection.html","page":"Selection operators","title":"Selection operators","text":"TournamentSelectionSteady\nTournamentSelectionGenerational\nTruncationSelectionSteady\nTruncationSelectionGenerational","category":"page"},{"location":"man/selection.html#EvoLP.TournamentSelectionSteady","page":"Selection operators","title":"EvoLP.TournamentSelectionSteady","text":"Tournament parent selection with tournament size k.\n\n\n\n\n\n","category":"type"},{"location":"man/selection.html#EvoLP.TournamentSelectionGenerational","page":"Selection operators","title":"EvoLP.TournamentSelectionGenerational","text":"Tournament parent selection with tournament size k.\n\n\n\n\n\n","category":"type"},{"location":"man/selection.html#EvoLP.TruncationSelectionSteady","page":"Selection operators","title":"EvoLP.TruncationSelectionSteady","text":"Truncation selection for selecting top k possible parents in the population.\n\n\n\n\n\n","category":"type"},{"location":"man/selection.html#EvoLP.TruncationSelectionGenerational","page":"Selection operators","title":"EvoLP.TruncationSelectionGenerational","text":"Truncation selection for selecting top k possible parents in the population.\n\n\n\n\n\n","category":"type"},{"location":"man/selection.html","page":"Selection operators","title":"Selection operators","text":"RouletteWheelSelectionSteady\nRouletteWheelSelectionGenerational\nRankBasedSelectionSteady\nRankBasedSelectionGenerational","category":"page"},{"location":"man/selection.html#EvoLP.RouletteWheelSelectionSteady","page":"Selection operators","title":"EvoLP.RouletteWheelSelectionSteady","text":"Roulette wheel parent selection.\n\n\n\n\n\n","category":"type"},{"location":"man/selection.html#EvoLP.RouletteWheelSelectionGenerational","page":"Selection operators","title":"EvoLP.RouletteWheelSelectionGenerational","text":"Roulette wheel parent selection.\n\n\n\n\n\n","category":"type"},{"location":"man/selection.html#EvoLP.RankBasedSelectionSteady","page":"Selection operators","title":"EvoLP.RankBasedSelectionSteady","text":"Rank-based parent selection.\n\n\n\n\n\n","category":"type"},{"location":"man/selection.html#EvoLP.RankBasedSelectionGenerational","page":"Selection operators","title":"EvoLP.RankBasedSelectionGenerational","text":"Rank-based parent selection.\n\n\n\n\n\n","category":"type"},{"location":"man/selection.html#Performing-the-selection","page":"Selection operators","title":"Performing the selection","text":"","category":"section"},{"location":"man/selection.html","page":"Selection operators","title":"Selection operators","text":"After \"instantiating\" a selection method, you can use the select function on an array of fitnesses y to obtain parents' indices (that you will need to slice from the population in your algorithm later.)","category":"page"},{"location":"man/selection.html","page":"Selection operators","title":"Selection operators","text":"select","category":"page"},{"location":"man/selection.html#EvoLP.select","page":"Selection operators","title":"EvoLP.select","text":"select(t::TruncationSelectionSteady, y)\n\nSelect two random parents out from the top t.k in the population.\n\n\n\n\n\nselect(t::TournamentSelectionSteady, y)\n\nSelect two parents which are the winners from two random tournaments of size t.k.\n\n\n\n\n\nselect(::RouletteWheelSelectionSteady, y)\n\nSelect two random parents with probability proportional to their fitness.\n\n\n\n\n\nselect(::RankBasedSelectionSteady, y)\n\nSelect two random parents with probability proportional to their ranks.\n\n\n\n\n\nselect(t::TruncationSelectionGenerational, y)\n\nSelect two random parents (from the top t.k) in the population for each fitness in y.\n\n\n\n\n\nselect(t::TournamentSelectionGenerational, y)\n\nSelect two parents which are the winners from two random tournaments of size t.k for each fitness in y.\n\n\n\n\n\nselect(::RouletteWheelSelectionGenerational, y)\n\nSelect two random parents with probability proportional to their fitness, for each fitness in y.\n\n\n\n\n\nselect(::RankBasedSelectionGenerational, y)\n\nSelect two random parents with probability proportional to their ranks, for each fitness in y.\n\n\n\n\n\n","category":"function"},{"location":"man/algorithms.html#Algorithms","page":"Algorithms","title":"Algorithms","text":"","category":"section"},{"location":"man/algorithms.html","page":"Algorithms","title":"Algorithms","text":"EvoLP provides some basic built-in algorithms to get you started. All algorithms are built for minimisation.","category":"page"},{"location":"man/algorithms.html#Evolutionary-Algorithms-(EA)","page":"Algorithms","title":"Evolutionary Algorithms (EA)","text":"","category":"section"},{"location":"man/algorithms.html","page":"Algorithms","title":"Algorithms","text":"The basic 1+1 EA starts with a vector individual and slowly finds its way to an optimum by only using mutation.","category":"page"},{"location":"man/algorithms.html","page":"Algorithms","title":"Algorithms","text":"oneplusone","category":"page"},{"location":"man/algorithms.html#EvoLP.oneplusone","page":"Algorithms","title":"EvoLP.oneplusone","text":"oneplusone(f, ind, k_max, M)\noneplusone(logger::Logbook, f, ind, k_max, M)\n\n1+1 Evolutionary Algorithm.\n\nArguments\n\nf::Function: objective function to minimise.\nind::AbstractVector: individual to start the evolution.\nk_max::Integer: number of iterations.\nM::MutationMethod: one of the available MutationMethod.\n\nReturns a Result.\n\n\n\n\n\n","category":"function"},{"location":"man/algorithms.html#Genetic-Algorithms-(GA)","page":"Algorithms","title":"Genetic Algorithms (GA)","text":"","category":"section"},{"location":"man/algorithms.html","page":"Algorithms","title":"Algorithms","text":"In a GA a population of vector solutions is simulated, where individuals get selected, recombined, and mutated. The built-in implementation in EvoLP is a generational GA taken from Kochenderfer, M.J. and Wheeler, T.A. 2019, which means the whole population is replaced by its offspring at every iteration.","category":"page"},{"location":"man/algorithms.html","page":"Algorithms","title":"Algorithms","text":"GA","category":"page"},{"location":"man/algorithms.html#EvoLP.GA","page":"Algorithms","title":"EvoLP.GA","text":"GA(f, pop, k_max, S, C, M)\nGA(logbook::Logbook, f, pop, k_max, S, C, M)\n\nGenerational Genetic Algorithm.\n\nArguments\n\nf::Function: objective function to minimise.\npop::AbstractVector: populationâa list of vector individuals.\nk_max::Integer: number of iterations.\nS::SelectionMethod: one of the available SelectionMethod.\nC::CrossoverMethod: one of the available CrossoverMethod.\nM::MutationMethod: one of the available MutationMethod.\n\nReturns a Result.\n\n\n\n\n\n","category":"function"},{"location":"man/algorithms.html#Particle-Swarm-Optimisation-(PSO)","page":"Algorithms","title":"Particle Swarm Optimisation (PSO)","text":"","category":"section"},{"location":"man/algorithms.html","page":"Algorithms","title":"Algorithms","text":"In PSO, individuals are particles with velocity and memory. At each iteration, a particle changes its velocity considering the neighbouring particles as well as the best position of the whole swarm.","category":"page"},{"location":"man/algorithms.html","page":"Algorithms","title":"Algorithms","text":"The built-in implementation in EvoLP is taken from Kochenderfer, M.J. and Wheeler, T.A. 2019.","category":"page"},{"location":"man/algorithms.html","page":"Algorithms","title":"Algorithms","text":"PSO","category":"page"},{"location":"man/algorithms.html#EvoLP.PSO","page":"Algorithms","title":"EvoLP.PSO","text":"PSO(f, population, k_max; w=1, c1=1, c2=1)\nPSO(logger::Logbook, f, population, k_max; w=1, c1=1, c2=1)\n\nArguments\n\nf::Function: Objective function to minimise.\npopulation::Vector{Particle}: a list of Particle individuals.\nk_max::Integer: number of iterations.\n\nKeywords\n\nw: inertia weight. Optional, by default 1.\nc1: cognitive coefficient (own's position). Optional, by default 1.\nc2: social coefficient (others' position). Optional, by default 1.\n\nReturns a Result.\n\n\n\n\n\n","category":"function"},{"location":"man/logbook.html#Statistics-Logbook","page":"Logging statistics","title":"Statistics Logbook","text":"","category":"section"},{"location":"man/logbook.html","page":"Logging statistics","title":"Logging statistics","text":"EvoLP includes a Logbook type which can be used to log statistics during runs.","category":"page"},{"location":"man/logbook.html","page":"Logging statistics","title":"Logging statistics","text":"Logbook","category":"page"},{"location":"man/logbook.html#EvoLP.Logbook","page":"Logging statistics","title":"EvoLP.Logbook","text":"Logbook(S::LittleDict)\n\nA log for statistics intended for use on every iteration of an algorithm. The logbook is constructed from a LittleDict ordered dictionary which maps stat names (strings) to callables, such that statname i can be computed from callable i.\n\nThe resulting Logbook contains:\n\nS::LittleDict: The ordered dict of stat names and callables\nrecords::AbstractVector: A vector of NamedTuples where each field is a statistic.\n\n\n\n\n\n","category":"type"},{"location":"man/logbook.html","page":"Logging statistics","title":"Logging statistics","text":"DocTestSetup = quote\n  using OrderedCollections\n  using Statistics\nend","category":"page"},{"location":"man/logbook.html","page":"Logging statistics","title":"Logging statistics","text":"The Logbook receives an OrderedCollections.jl LittleDict (ordered dictionary for a small number of items) with the following format:","category":"page"},{"location":"man/logbook.html","page":"Logging statistics","title":"Logging statistics","text":"LittleDict(\"statname\"::String => callable::Function)","category":"page"},{"location":"man/logbook.html","page":"Logging statistics","title":"Logging statistics","text":"For example, using some of the Statistics built-in functions:","category":"page"},{"location":"man/logbook.html","page":"Logging statistics","title":"Logging statistics","text":"julia> statnames = [\"mean_eval\", \"max_f\", \"min_f\", \"median_f\"];\n\njulia> fns = [mean, maximum, minimum, median];\n\njulia> thedict = LittleDict(statnames, fns)\nLittleDict{String, Function, Vector{String}, Vector{Function}} with 4 entries:\n  \"mean_eval\" => mean\n  \"max_f\"     => maximum\n  \"min_f\"     => minimum\n  \"median_f\"  => median","category":"page"},{"location":"man/logbook.html","page":"Logging statistics","title":"Logging statistics","text":"Then the logbook can be constructed:","category":"page"},{"location":"man/logbook.html","page":"Logging statistics","title":"Logging statistics","text":"julia> thelogger = Logbook(thedict)\nLogbook(LittleDict{AbstractString, Function, Vector{AbstractString}, Vector{Function}}(\"mean_eval\" => Statistics.mean, \"max_f\" => maximum, \"min_f\" => minimum, \"median_f\" => Statistics.median), NamedTuple{(:mean_eval, :max_f, :min_f, :median_f)}[])","category":"page"},{"location":"man/logbook.html#Computing-statistics","page":"Logging statistics","title":"Computing statistics","text":"","category":"section"},{"location":"man/logbook.html","page":"Logging statistics","title":"Logging statistics","text":"After instantiating the Logbook, you can use the compute! function on each iteration of an algorithm. The statistics are stored in the records field inside the Logbook, which is a vector of records (NamedTuples). This makes it easier to export as a DataFrame.","category":"page"},{"location":"man/logbook.html","page":"Logging statistics","title":"Logging statistics","text":"compute!","category":"page"},{"location":"man/logbook.html#EvoLP.compute!","page":"Logging statistics","title":"EvoLP.compute!","text":"compute!(logger::Logbook, data::AbstractVector)\n\nComputes statistics for logger using data, which is usually a vector of fitnesses. All calculations are done in place, so logger will be updated.\n\n\n\n\n\n","category":"function"},{"location":"tuto/8_queen.html#Solving-the-8-queens-problem","page":"The 8 queens problem","title":"Solving the 8-queens problem","text":"","category":"section"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"This tutorial will showcase how to use some of the building blocks provided by LP to solve a combinatorial problem.","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"In this example,  we will solve the 8-queens puzzle. This is a constraint satisfaction problem in which the goal is to place 8 queens in a chess board such that neither of them check each other.","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"DocTestSetup = quote\n  using EvoLP\n  using OrderedCollections\n  using Statistics\nend","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"(Image: One queen on the board)","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"In the figure above, we have placed a queen represented by a blue dot. All conflicting cells have been highlighted. The problem becomes harder when we add more queens to the board:","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"(Image: 2 queens on the board)","category":"page"},{"location":"tuto/8_queen.html#Implementing-the-solution","page":"The 8 queens problem","title":"Implementing the solution","text":"","category":"section"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"We can solve this problem using a Genetic Algorithm (GA) that deals with the constraints, using a steady-state approach and logging statistics on every iteration.","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"We will use the following modules:","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"using Statistics\nusing EvoLP\nusing OrderedCollections","category":"page"},{"location":"tuto/8_queen.html#Dealing-with-constraints","page":"The 8 queens problem","title":"Dealing with constraints","text":"","category":"section"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"To implement the solution, we need to handle the constraints in some way. For this problem, we can divide the constraints in vertical, horizontal and diagonal clashes between the queens.","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"Interestingly enough, the vertical and horizontal clashes can be dealt with by using a vector of permutations where the genes (index of the vector) represent a column and the alleles (values the index can take) represent the row used in that column:","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"(Image: A possible representation of the 8-queen problem)","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"For the phenotype above, the genotype representation would look like this:","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"x = [1, 3, 5, 2, 6, 4, 7, 8]","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"The queen in the first column is in row 1. The queen in the second column is in row 3, and so on.","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"EvoLP contains a convenient permutation_vector_pop:","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"permutation_vector_pop","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"julia> @doc permutation_vector_pop","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"We can now use the generator to initialise our population:","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"pop_size = 100\npopulation = permutation_vector_pop(pop_size, 8, 1:8)\nfirst(population, 3)","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"3-element Vector{Vector{Int64}}:\n    [3, 7, 4, 8, 2, 1, 5, 6]\n    [5, 4, 7, 6, 2, 3, 1, 8]\n    [8, 6, 5, 1, 2, 3, 4, 7]","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"To deal with the diagonal constraints, we can use the fitness function.","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"The penalty of a queen is the number of queens she can check. The penalty of a board configuration would then be the sum of all penalties of all queens, and this is what we want to minimise. So let's build our fitness function step by step.","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"Assume a queen q is in a position (i j). Then, we can define the diagonal neighbourhood as the following:","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"Top-left: (i-1 j-1)\nTop-right: (i-1 j+1)\nBottom-left: (i+1 j-1)\nBottom-right: (i+1 j+1)","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"We can then use this information to iterate in all directions and check how many queens are there in the diagonals.","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"If we do this for every queen q, then we will count some of the clashes twice. It is a good idea to create a set of these clashes so that we can sum them afterwards.","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"function diag_constraints(x)\n    # rows are values in x\n    # columns are indices from 1:8\n    fitness = []\n    for q in 1:8\n        tl = collect(zip(x[q]:-1:1, q:-1:1))\n        tr = collect(zip(x[q]:-1:1, q:1:8))\n        bl = collect(zip(x[q]:1:8, q:-1:1))\n        br = collect(zip(x[q]:1:8, q:1:8))\n\n        constraints = Set(vcat(tl, tr, bl, br))\n        delete!(constraints, (x[q], q))\n        q_fit = sum([(i, j) in constraints ? 1 : 0 for (i, j) in zip(x, 1:8)])\n        push!(fitness, q_fit)\n    end\n\n    return sum(fitness)\nend","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"To handle the corners and not specify \"emtpy\" diagonals, we consider the position (ij) of a queen to count as a \"clash\" itself. This means that a queen in (11) will consider (11) as the top-left diagonal, and (ii) i in 18 as the bottom-right diagonal (again, including itself). We later remove these additional constraints via delete! and proceed normally.","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"Using the same configuration as before, we have the following conflicting positions:","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"(Image: Conflicts of the previous configuration are highlighted)","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"We can test our fitness function diag_constraints on this board and see the number of conflicts in total:","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"test = [1, 3, 5, 2, 6, 4, 7, 8]\ndiag_constraints(test)","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"10","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"Going through each queen q_i (with i being the column number), we have the following number of conflicts: q_1 = 2, q_2 = 1, q_3 = 0, q_4 = 1, q_5 = 1, q_6 = 1, q_7 = 2,  q_8 = 2","category":"page"},{"location":"tuto/8_queen.html#Evolutionary-operators","page":"The 8 queens problem","title":"Evolutionary operators","text":"","category":"section"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"We now need to choose our evolutionary operators: what we will use for selection, crossover and mutation.","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"However, since we're dealing with permutations, we are restricted to use specific operators that do not end up destroying feasible solutions and therefore violate our constraints. EvoLP contains some operators that can deal with permutation-based individuals:","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"julia> @doc TournamentSelectionSteady","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"Tournament parent selection with tournament size ``k``.","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"julia> @doc OrderOneCrossover","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"Order 1 crossover (OX1) for permutation-based individuals.","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"julia> @doc SwapMutation","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"Swap mutation for permutation-based individuals.","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"We can now instantiate them and continue.","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"S = TournamentSelectionSteady(5);\nC = OrderOneCrossover();\nM = SwapMutation();","category":"page"},{"location":"tuto/8_queen.html#Logging-statistics","page":"The 8 queens problem","title":"Logging statistics","text":"","category":"section"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"We can use the Logbook to record statistics about our run:","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"statnames = [\"mean_eval\", \"max_f\", \"min_f\", \"median_f\"]\nfns = [mean, maximum, minimum, median]\nthedict = LittleDict(statnames, fns)\nthelogger = Logbook(thedict)","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"Logbook(LittleDict{AbstractString, Function, Vector{AbstractString}, Vector{Function}}(\"mean_eval\" => Statistics.mean, \"max_f\" => maximum, \"min_f\" => minimum, \"median_f\" => Statistics.median), NamedTuple{(:mean_eval, :max_f, :min_f, :median_f)}[])","category":"page"},{"location":"tuto/8_queen.html#Constructing-our-own-algorithm","page":"The 8 queens problem","title":"Constructing our own algorithm","text":"","category":"section"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"And now we are ready to use all our building blocks to construct our own algorithm. In this case, we will use a steady-state GA: instead of replacing the whole population, we will generate a fixed amount of candidate solutions and keep the best n individuals in the population each iteration.","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"Let's do a summary then:","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"The representation is a vector of permutations of integers with values in the closed range 18.\nTo select the parents, we use the TournamentSelectionSteady operator with a tournament size of 5.\nTo recombine the parents, we use the OrderOneCrossover operator.\nTo mutate a candidate solution, we use the SwapMutation operator.\nTo select the survivors, we replace the worst individuals.\nWith a population size pop_size of 100.\nWith a random initialisation using the generator permutation_vector_pop.\nWe will use a crossover probability of 100%.\nAnd a mutation probability of 80%.","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"We can then build our algorithm in a function, and use EvoLP's Result type for the return:","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"function mySteadyGA(logbook, f, pop, k_max, S, C, M, mrate)\n    n = length(pop)\n    # Generation loop\n    for _ in 1:k_max\n        fitnesses = f.(pop)\n        parents = select(S, fitnesses)  # this will return 2 parents\n        parents = vcat(parents, select(S, fitnesses))  # Extend the list with 2 more parents\n        offspring = [cross(C, pop[parents[1]], pop[parents[2]])]  # get first kid\n        offspring = vcat(offspring, [cross(C, pop[parents[3]], pop[parents[4]])])  # get 2nd\n        pop = vcat(pop, offspring) # add to population\n        \n        # Mutation loop\n        for i in eachindex(pop)\n            if rand() <= mrate\n                pop[i] = mutate(M, pop[i])\n            end\n        end\n        fitnesses = f.(pop)\n\n        # Log statistics\n        compute!(logbook, fitnesses)\n\n        # Find worst and remove\n        worst1 = argmax(fitnesses)\n        deleteat!(pop, worst1)\n        deleteat!(fitnesses, worst1)\n        \n        # And do the same again\n        worst2 = argmax(fitnesses)\n        deleteat!(pop, worst2)\n        deleteat!(fitnesses, worst2)\n    end\n\n    # Result reporting\n    best, best_i = findmin(f, pop)\n    n_evals = 2 * k_max * n + n\n    result = Result(best, pop[best_i], pop, k_max, n_evals)\n    return result\nend","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"To try our new algorithm, we just need to call its function with the appropriate arguments:","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"result  = mySteadyGA(thelogger, diag_constraints, population, 500, S, C, M, 0.8);","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"EvoLP provides convenient functions that we can use to get information about a result:","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"@show optimum(result)\n@show optimizer(result)\n@show f_calls(result)\nthelogger.records[end]","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"optimum(result) = 0\noptimizer(result) = Any[5, 1, 8, 6, 3, 7, 2, 4]\nf_calls(result) = 100100\n\n\n\n(mean_eval = 9.392156862745098, max_f = 20, min_f = 0, median_f = 8.0)","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"And this is just a helper function to visualise our result as a chess board:","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"function drawboard(x)\n    b = fill(\"â»\",8,8)\n    for i in 1:2:8\n        b[i,2:2:8] .= \"â¼\"\n    end\n    for i in 2:2:8\n        b[i, 1:2:8] .= \"â¼\"\n    end\n    for (i,j) in zip(x,1:8)\n        b[i, j] = \"â\"\n    end\n    for i in 1:8\n        println(join(b[i,:]))\n    end\nend","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"drawboard(optimizer(result))","category":"page"},{"location":"tuto/8_queen.html","page":"The 8 queens problem","title":"The 8 queens problem","text":"â»ââ»â¼â»â¼â»â¼\nâ¼â»â¼â»â¼â»ââ»\nâ»â¼â»â¼ââ¼â»â¼\nâ¼â»â¼â»â¼â»â¼â\nââ¼â»â¼â»â¼â»â¼\nâ¼â»â¼ââ¼â»â¼â»\nâ»â¼â»â¼â»ââ»â¼\nâ¼â»ââ»â¼â»â¼â»","category":"page"},{"location":"index.html#EvoLP-An-evolutionary-computation-playground","page":"Introduction","title":"EvoLP - An evolutionary computation playground","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Welcome to the documentation for EvoLP!","category":"page"},{"location":"index.html#What-is-EvoLP?","page":"Introduction","title":"What is EvoLP?","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"EvoLP is a playground for evolutionary computation in Julia. It provides a set of predefined building blocks that can be coupled together to quickly generate evolutionary computation solvers and compute statistics for a variety of optimisation tasks, including discrete, continuous and combinatorial optimisation.","category":"page"},{"location":"index.html#Features","page":"Introduction","title":"Features","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Random population generators (vectors and particles)\nParent selection operators\nSeveral crossover and mutation methods\nTest functions for benchmarking\nConvenient result reporting and a statistics logbook","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Combine these blocks to make your own algorithms or use some of the included minimisers: GA, 1+1EA and PSO. Additionally, you can extend EvoLP to create new operators.","category":"page"},{"location":"index.html#Getting-started","page":"Introduction","title":"Getting started","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"note: Note\nTODO: Submit it to the package repository and make it installable.","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Read the quick start page.\nBrowse some of the examples to see how to use the built-in algorithms.\nFor a more comprehensive tutorial, read the 8-queen problem where we make an algorithm from scratch.","category":"page"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"Alternatively, you can browse the type and functions indices to view all available functionality.","category":"page"},{"location":"index.html#Acknowledgements","page":"Introduction","title":"Acknowledgements","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"EvoLP was initially created as a toolbox for internal use by PhD students of NTNU's Open AI Lab, and whose funding is provided by Project no. 311284 by The Research Council of Norway.","category":"page"},{"location":"index.html#License","page":"Introduction","title":"License","text":"","category":"section"},{"location":"index.html","page":"Introduction","title":"Introduction","text":"EvoLP is licensed under the MIT License which makes it free and open source.","category":"page"}]
}
